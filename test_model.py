"""
æµ‹è¯•è„šæœ¬ - Quantized Diffusion Model
Test script for quantized diffusion model

è¿è¡Œå„ç§æµ‹è¯•ä»¥éªŒè¯æ¨¡å‹å®ç°çš„æ­£ç¡®æ€§
"""

import torch
import torch.nn as nn
import numpy as np
import time
from pathlib import Path

from quantized_diffusion_model import (
    VectorQuantizer,
    QuantizedDiffusionPredictor,
    QuantizedDiffusionDMD,
    TransformerBlock,
)
from utils import count_parameters, format_number, MetricsTracker


def test_vector_quantizer():
    """æµ‹è¯•å‘é‡é‡åŒ–å™¨"""
    print("\n" + "="*60)
    print("Testing VectorQuantizer...")
    print("="*60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»º VQ
    vq = VectorQuantizer(
        num_embeddings=1024,
        embedding_dim=256,
    ).to(device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    B, C, F, H, W = 2, 256, 4, 8, 8
    z = torch.randn(B, C, F, H, W, device=device)
    
    z_q, vq_loss, indices = vq(z)
    
    # éªŒè¯å½¢çŠ¶
    assert z_q.shape == z.shape, f"Shape mismatch: {z_q.shape} vs {z.shape}"
    assert indices.shape == (B, F, H, W), f"Indices shape mismatch: {indices.shape}"
    assert vq_loss.item() >= 0, "VQ loss should be non-negative"
    
    # éªŒè¯é‡åŒ–
    assert torch.allclose(z_q, z, atol=1.0), "Quantized output too different from input"
    
    # æµ‹è¯•ç¼–ç /è§£ç 
    z_reconstructed = vq.get_codebook_entry(indices)
    assert z_reconstructed.shape == z.shape, "Reconstruction shape mismatch"
    
    print(f"âœ“ Input shape: {z.shape}")
    print(f"âœ“ Output shape: {z_q.shape}")
    print(f"âœ“ Indices shape: {indices.shape}")
    print(f"âœ“ VQ loss: {vq_loss.item():.4f}")
    print(f"âœ“ Unique codes used: {len(torch.unique(indices))}/{vq.num_embeddings}")
    print("âœ“ VectorQuantizer test passed!")


def test_transformer_block():
    """æµ‹è¯• Transformer å—"""
    print("\n" + "="*60)
    print("Testing TransformerBlock...")
    print("="*60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»º Transformer å—
    block = TransformerBlock(
        hidden_dim=512,
        num_heads=8,
        dropout=0.1,
    ).to(device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    B, F, N, D = 2, 4, 64, 512
    x = torch.randn(B, F, N, D, device=device)
    
    output = block(x)
    
    # éªŒè¯å½¢çŠ¶
    assert output.shape == x.shape, f"Shape mismatch: {output.shape} vs {x.shape}"
    
    # éªŒè¯æ¢¯åº¦æµ
    loss = output.mean()
    loss.backward()
    
    has_grad = any(p.grad is not None for p in block.parameters())
    assert has_grad, "No gradients computed"
    
    print(f"âœ“ Input shape: {x.shape}")
    print(f"âœ“ Output shape: {output.shape}")
    print(f"âœ“ Parameters: {format_number(sum(p.numel() for p in block.parameters()))}")
    print("âœ“ TransformerBlock test passed!")


def test_quantized_diffusion_predictor():
    """æµ‹è¯•é‡åŒ–æ‰©æ•£é¢„æµ‹å™¨"""
    print("\n" + "="*60)
    print("Testing QuantizedDiffusionPredictor...")
    print("="*60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = QuantizedDiffusionPredictor(
        latent_channels=16,
        num_embeddings=1024,
        embedding_dim=256,
        hidden_dim=512,
        num_layers=4,
        num_heads=8,
        dropout=0.1,
        max_frames=32,
    ).to(device)
    
    total_params, trainable_params = count_parameters(model)
    print(f"Model parameters: {format_number(total_params)}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆå¸¦é‡åŒ–ï¼‰
    B, C, F, H, W = 2, 16, 8, 16, 16
    x = torch.randn(B, C, F, H, W, device=device)
    timesteps = torch.randint(0, 1000, (B,), device=device)
    
    output = model(x, timesteps, return_quantized=True)
    
    # éªŒè¯è¾“å‡º
    assert 'pred' in output, "Missing 'pred' in output"
    assert 'vq_loss' in output, "Missing 'vq_loss' in output"
    assert 'indices' in output, "Missing 'indices' in output"
    
    pred = output['pred']
    vq_loss = output['vq_loss']
    indices = output['indices']
    
    assert pred.shape[0] == B, "Batch size mismatch"
    assert indices.shape == (B, F, H, W), f"Indices shape mismatch: {indices.shape}"
    
    print(f"âœ“ Input shape: {x.shape}")
    print(f"âœ“ Prediction shape: {pred.shape}")
    print(f"âœ“ Indices shape: {indices.shape}")
    print(f"âœ“ VQ loss: {vq_loss.item():.4f}")
    
    # æµ‹è¯•ç¼–ç /è§£ç 
    indices_encoded = model.encode_to_indices(x, timesteps)
    assert indices_encoded.shape == indices.shape, "Encoding shape mismatch"
    
    decoded = model.decode_from_indices(indices)
    print(f"âœ“ Decoded shape: {decoded.shape}")
    
    # æµ‹è¯•æ¢¯åº¦æµ
    loss = pred.mean() + vq_loss
    loss.backward()
    
    has_grad = any(p.grad is not None for p in model.parameters() if p.requires_grad)
    assert has_grad, "No gradients computed"
    
    print("âœ“ QuantizedDiffusionPredictor test passed!")


def test_quantized_diffusion_dmd():
    """æµ‹è¯• DMD è®­ç»ƒåŒ…è£…å™¨"""
    print("\n" + "="*60)
    print("Testing QuantizedDiffusionDMD...")
    print("="*60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = QuantizedDiffusionPredictor(
        latent_channels=16,
        num_embeddings=512,
        embedding_dim=128,
        hidden_dim=256,
        num_layers=2,
        num_heads=4,
        dropout=0.0,
        max_frames=16,
    ).to(device)
    
    # åˆ›å»º DMD åŒ…è£…å™¨
    dmd = QuantizedDiffusionDMD(
        model=model,
        device=device,
        num_train_timesteps=1000,
        min_step=20,
        max_step=980,
        beta_schedule='linear',
        quantization_weight=0.1,
    )
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    B, C, F, H, W = 2, 16, 4, 8, 8
    x_0 = torch.randn(B, C, F, H, W, device=device)
    
    loss, metrics = dmd.compute_loss(x_0)
    
    # éªŒè¯æŸå¤±
    assert loss.item() >= 0, "Loss should be non-negative"
    assert 'denoising_loss' in metrics, "Missing denoising_loss"
    assert 'vq_loss' in metrics, "Missing vq_loss"
    
    print(f"âœ“ Loss: {loss.item():.4f}")
    print(f"âœ“ Denoising loss: {metrics['denoising_loss']:.4f}")
    print(f"âœ“ VQ loss: {metrics['vq_loss']:.4f}")
    
    # æµ‹è¯•æ¢¯åº¦
    loss.backward()
    has_grad = any(p.grad is not None for p in model.parameters() if p.requires_grad)
    assert has_grad, "No gradients computed"
    
    # æµ‹è¯•é‡‡æ ·
    print("\nTesting sampling...")
    model.eval()
    with torch.no_grad():
        samples = dmd.sample(
            shape=(1, C, F, H, W),
            num_inference_steps=10,
        )
    
    assert samples.shape == (1, C, F, H, W), f"Sample shape mismatch: {samples.shape}"
    print(f"âœ“ Sample shape: {samples.shape}")
    
    print("âœ“ QuantizedDiffusionDMD test passed!")


def test_training_step():
    """æµ‹è¯•å®Œæ•´çš„è®­ç»ƒæ­¥éª¤"""
    print("\n" + "="*60)
    print("Testing Training Step...")
    print("="*60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = QuantizedDiffusionPredictor(
        latent_channels=16,
        num_embeddings=256,
        embedding_dim=128,
        hidden_dim=256,
        num_layers=2,
        num_heads=4,
        dropout=0.0,
    ).to(device)
    
    # åˆ›å»º DMD
    dmd = QuantizedDiffusionDMD(
        model=model,
        device=device,
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    
    # è®­ç»ƒå‡ æ­¥
    model.train()
    tracker = MetricsTracker()
    
    num_steps = 5
    B, C, F, H, W = 2, 16, 4, 8, 8
    
    print(f"\nRunning {num_steps} training steps...")
    start_time = time.time()
    
    for step in range(num_steps):
        # ç”Ÿæˆéšæœºæ•°æ®
        x_0 = torch.randn(B, C, F, H, W, device=device)
        
        # å‰å‘ä¼ æ’­
        loss, metrics = dmd.compute_loss(x_0)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # è®°å½•æŒ‡æ ‡
        tracker.update(metrics)
        
        if step % 2 == 0:
            print(f"  Step {step}: loss={loss.item():.4f}")
    
    elapsed = time.time() - start_time
    
    print(f"\nâœ“ Completed {num_steps} steps in {elapsed:.2f}s")
    print(f"âœ“ Average metrics: {tracker}")
    print("âœ“ Training step test passed!")


def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("\n" + "="*60)
    print("Testing Memory Usage...")
    print("="*60)
    
    if not torch.cuda.is_available():
        print("âš  CUDA not available, skipping memory test")
        return
    
    device = torch.device('cuda')
    
    # æ¸…ç©ºç¼“å­˜
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    # åˆ›å»ºæ¨¡å‹
    model = QuantizedDiffusionPredictor(
        latent_channels=16,
        num_embeddings=1024,
        embedding_dim=256,
        hidden_dim=512,
        num_layers=4,
        num_heads=8,
    ).to(device)
    
    model_memory = torch.cuda.memory_allocated() / (1024 ** 2)
    print(f"âœ“ Model memory: {model_memory:.2f} MB")
    
    # å‰å‘ä¼ æ’­
    B, C, F, H, W = 4, 16, 8, 16, 16
    x = torch.randn(B, C, F, H, W, device=device)
    timesteps = torch.randint(0, 1000, (B,), device=device)
    
    output = model(x, timesteps, return_quantized=True)
    
    forward_memory = torch.cuda.memory_allocated() / (1024 ** 2)
    print(f"âœ“ Forward pass memory: {forward_memory:.2f} MB")
    
    # åå‘ä¼ æ’­
    loss = output['pred'].mean() + output['vq_loss']
    loss.backward()
    
    backward_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)
    print(f"âœ“ Peak memory (with gradients): {backward_memory:.2f} MB")
    
    print("âœ“ Memory usage test passed!")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("Running All Tests for Quantized Diffusion Model")
    print("="*60)
    
    tests = [
        ("VectorQuantizer", test_vector_quantizer),
        ("TransformerBlock", test_transformer_block),
        ("QuantizedDiffusionPredictor", test_quantized_diffusion_predictor),
        ("QuantizedDiffusionDMD", test_quantized_diffusion_dmd),
        ("Training Step", test_training_step),
        ("Memory Usage", test_memory_usage),
    ]
    
    passed = 0
    failed = 0
    
    for name, test_fn in tests:
        try:
            test_fn()
            passed += 1
        except Exception as e:
            print(f"\nâœ— {name} test FAILED!")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
            failed += 1
    
    print("\n" + "="*60)
    print("Test Summary")
    print("="*60)
    print(f"Passed: {passed}/{len(tests)}")
    print(f"Failed: {failed}/{len(tests)}")
    
    if failed == 0:
        print("\nğŸ‰ All tests passed!")
    else:
        print(f"\nâš  {failed} test(s) failed")
    
    print("="*60)


if __name__ == '__main__':
    run_all_tests()

