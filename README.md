# Quantized Diffusion Model for Video Generation
# åŸºäº Diffusion çš„é‡åŒ–é¢„æµ‹æ¨¡å‹

è¿™æ˜¯ä¸€ä¸ªåŸºäº Diffusion å’Œ Distribution Matching Distillation (DMD) çš„é‡åŒ–é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºé«˜æ•ˆçš„è§†é¢‘ç”Ÿæˆã€‚

## ğŸ“‹ ç›®å½•ç»“æ„

```
openveo3_dmd/0/
â”œâ”€â”€ quantized_diffusion_model.py   # æ ¸å¿ƒæ¨¡å‹å®ç°
â”œâ”€â”€ train_quantized_dmd.py         # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference_quantized.py         # æ¨ç†è„šæœ¬
â”œâ”€â”€ config.py                       # é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨
â”œâ”€â”€ README.md                       # æœ¬æ–‡ä»¶
â””â”€â”€ configs/                        # é…ç½®æ–‡ä»¶ç›®å½•ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
```

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

### 1. **å‘é‡é‡åŒ– (Vector Quantization)**
- ä½¿ç”¨ VQ-VAE é£æ ¼çš„ç¦»æ•£ç¼–ç æœ¬
- æ”¯æŒ EMA æ›´æ–°ç­–ç•¥
- å¯é…ç½®çš„ç¼–ç æœ¬å¤§å°ï¼ˆ4K-16Kï¼‰

### 2. **Diffusion å»å™ªè¿‡ç¨‹**
- æ”¯æŒçº¿æ€§å’Œä½™å¼¦å™ªå£°è°ƒåº¦
- DDIM é‡‡æ ·åŠ é€Ÿæ¨ç†
- å¯é…ç½®çš„æ—¶é—´æ­¥èŒƒå›´

### 3. **DMD è®­ç»ƒç­–ç•¥**
- Distribution Matching Distillation
- é«˜æ•ˆçš„çŸ¥è¯†è’¸é¦
- æ”¯æŒæ¢¯åº¦ç´¯ç§¯å’Œæ··åˆç²¾åº¦è®­ç»ƒ

### 4. **Transformer æ¶æ„**
- å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
- æ—¶ç©ºå»ºæ¨¡èƒ½åŠ›
- ä½ç½®ç¼–ç å’Œæ—¶é—´æ­¥åµŒå…¥

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç”Ÿæˆé…ç½®æ–‡ä»¶

```bash
cd /inspire/ssd/project/video-generation/public/openveo3/openveo3_dmd/0
python config.py
```

è¿™å°†ç”Ÿæˆ 4 ä¸ªé¢„è®¾é…ç½®ï¼š
- `config_small.json` - å°æ¨¡å‹ï¼Œå¿«é€Ÿæµ‹è¯•
- `config_medium.json` - ä¸­ç­‰æ¨¡å‹ï¼Œæ ‡å‡†è®­ç»ƒ
- `config_large.json` - å¤§æ¨¡å‹ï¼Œé«˜è´¨é‡ç”Ÿæˆ
- `config_dmd_optimized.json` - DMD ä¼˜åŒ–é…ç½®

### 2. è®­ç»ƒæ¨¡å‹

#### å• GPU è®­ç»ƒ
```bash
python train_quantized_dmd.py \
    --config configs/config_small.json
```

#### å¤š GPU è®­ç»ƒï¼ˆæ¨èï¼‰
```bash
torchrun --nproc_per_node=8 \
    train_quantized_dmd.py \
    --config configs/config_medium.json
```

#### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
```bash
python train_quantized_dmd.py \
    --config configs/config_medium.json \
    --resume outputs/quantized_dmd_medium/checkpoint_step_5000.pt
```

### 3. æ¨ç†ç”Ÿæˆ

#### åŸºæœ¬æ¨ç†
```bash
python inference_quantized.py \
    --checkpoint outputs/quantized_dmd_medium/final_checkpoint.pt \
    --output_dir outputs/inference \
    --num_samples 5 \
    --num_frames 16 \
    --height 256 \
    --width 256
```

#### å¸¦å¯è§†åŒ–çš„æ¨ç†
```bash
python inference_quantized.py \
    --checkpoint outputs/quantized_dmd_medium/final_checkpoint.pt \
    --output_dir outputs/inference \
    --num_samples 5 \
    --visualize \
    --analyze_codebook
```

## ğŸ“Š æ¨¡å‹æ¶æ„

### æ ¸å¿ƒç»„ä»¶

1. **VectorQuantizer**
   - ç¼–ç æœ¬å¤§å°ï¼š4096-16384
   - åµŒå…¥ç»´åº¦ï¼š256-768
   - EMA è¡°å‡ï¼š0.99

2. **QuantizedDiffusionPredictor**
   - è¾“å…¥æŠ•å½±ï¼šConv3D
   - Transformer å—ï¼š6-24 å±‚
   - è¾“å‡ºæŠ•å½±ï¼šConv3D + é‡åŒ–

3. **TransformerBlock**
   - å¤šå¤´è‡ªæ³¨æ„åŠ›
   - å‰é¦ˆç½‘ç»œï¼ˆ4x æ‰©å±•ï¼‰
   - LayerNorm + æ®‹å·®è¿æ¥

### è®­ç»ƒæµç¨‹

```
è¾“å…¥ x_0 (clean latent)
    â†“
é‡‡æ ·æ—¶é—´æ­¥ t
    â†“
æ·»åŠ å™ªå£° â†’ x_t
    â†“
æ¨¡å‹é¢„æµ‹ â†’ pred_x0
    â†“
å‘é‡é‡åŒ– â†’ z_q, indices
    â†“
è®¡ç®—æŸå¤±ï¼š
  - å»å™ªæŸå¤±ï¼šMSE(pred_x0, x_0)
  - VQ æŸå¤±ï¼šcommitment + codebook
    â†“
åå‘ä¼ æ’­ + ä¼˜åŒ–
```

## ğŸ”§ é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®
```json
{
  "model": {
    "latent_channels": 16,        // æ½œåœ¨ç©ºé—´é€šé“æ•°
    "num_embeddings": 8192,       // ç¼–ç æœ¬å¤§å°
    "embedding_dim": 512,         // åµŒå…¥ç»´åº¦
    "hidden_dim": 1024,           // éšè—å±‚ç»´åº¦
    "num_layers": 12,             // Transformer å±‚æ•°
    "num_heads": 16,              // æ³¨æ„åŠ›å¤´æ•°
    "dropout": 0.1,               // Dropout ç‡
    "max_frames": 64              // æœ€å¤§å¸§æ•°
  }
}
```

### Diffusion é…ç½®
```json
{
  "diffusion": {
    "num_train_timesteps": 1000,  // è®­ç»ƒæ—¶é—´æ­¥æ•°
    "min_step": 20,                // æœ€å°æ—¶é—´æ­¥
    "max_step": 980,               // æœ€å¤§æ—¶é—´æ­¥
    "beta_schedule": "linear"      // å™ªå£°è°ƒåº¦ç±»å‹
  }
}
```

### è®­ç»ƒé…ç½®
```json
{
  "training": {
    "num_epochs": 100,                    // è®­ç»ƒè½®æ•°
    "batch_size": 4,                      // æ‰¹æ¬¡å¤§å°
    "learning_rate": 1e-4,                // å­¦ä¹ ç‡
    "gradient_accumulation_steps": 2,     // æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    "warmup_steps": 1000,                 // é¢„çƒ­æ­¥æ•°
    "quantization_weight": 0.1            // VQ æŸå¤±æƒé‡
  }
}
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å†…å­˜ä¼˜åŒ–
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å‡å°‘æ‰¹æ¬¡å¤§å°
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16/BF16ï¼‰
- ä½¿ç”¨ FSDP è¿›è¡Œå¤§æ¨¡å‹è®­ç»ƒ

### 2. è®­ç»ƒåŠ é€Ÿ
- å¢åŠ  num_workers æé«˜æ•°æ®åŠ è½½é€Ÿåº¦
- ä½¿ç”¨å¤š GPU å¹¶è¡Œè®­ç»ƒ
- è°ƒæ•´ min_step/max_step å‡å°‘è®¡ç®—é‡

### 3. è´¨é‡æå‡
- å¢å¤§ç¼–ç æœ¬å¤§å°ï¼ˆ8K â†’ 16Kï¼‰
- ä½¿ç”¨ä½™å¼¦å™ªå£°è°ƒåº¦
- é™ä½ quantization_weightï¼ˆ0.1 â†’ 0.05ï¼‰
- å¢åŠ æ¨¡å‹æ·±åº¦å’Œå®½åº¦

## ğŸ”¬ å®éªŒå»ºè®®

### æ¶ˆèå®éªŒ

1. **ç¼–ç æœ¬å¤§å°**
   ```bash
   # æµ‹è¯•ä¸åŒç¼–ç æœ¬å¤§å°ï¼š4096, 8192, 16384
   python train_quantized_dmd.py --config config_4k.json
   python train_quantized_dmd.py --config config_8k.json
   python train_quantized_dmd.py --config config_16k.json
   ```

2. **é‡åŒ–æŸå¤±æƒé‡**
   ```python
   # åœ¨ config ä¸­ä¿®æ”¹
   "quantization_weight": [0.05, 0.1, 0.2, 0.5]
   ```

3. **æ—¶é—´æ­¥èŒƒå›´**
   ```python
   # æµ‹è¯•ä¸åŒèŒƒå›´
   "min_step": [20, 50, 100]
   "max_step": [900, 950, 980]
   ```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè®°å½•ä»¥ä¸‹æŒ‡æ ‡ï¼š

- **loss**: æ€»æŸå¤±
- **denoising_loss**: å»å™ªæŸå¤±ï¼ˆMSEï¼‰
- **vq_loss**: å‘é‡é‡åŒ–æŸå¤±
- **codebook_usage**: ç¼–ç æœ¬ä½¿ç”¨ç‡
- **perplexity**: ç¼–ç æœ¬å›°æƒ‘åº¦

æ¨ç†æ—¶å¯ä»¥åˆ†æï¼š
- ç¼–ç æœ¬ä½¿ç”¨ç»Ÿè®¡
- ç”Ÿæˆè´¨é‡ï¼ˆFVD, IS ç­‰ï¼‰
- æ¨ç†é€Ÿåº¦ï¼ˆFPSï¼‰

## ğŸ› å¸¸è§é—®é¢˜

### 1. OOM (Out of Memory)
```bash
# è§£å†³æ–¹æ¡ˆï¼š
# - å‡å° batch_size
# - å¢åŠ  gradient_accumulation_steps
# - å‡å°æ¨¡å‹å°ºå¯¸ï¼ˆhidden_dim, num_layersï¼‰
# - å‡å°è¾“å…¥åˆ†è¾¨ç‡
```

### 2. ç¼–ç æœ¬å´©æºƒ
```python
# ç—‡çŠ¶ï¼šåªä½¿ç”¨å°‘æ•°å‡ ä¸ªç¼–ç 
# è§£å†³æ–¹æ¡ˆï¼š
# - é™ä½ commitment_cost
# - å¢åŠ  EMA decay
# - ä½¿ç”¨æ›´å¤§çš„ç¼–ç æœ¬
# - å¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§
```

### 3. è®­ç»ƒä¸ç¨³å®š
```python
# è§£å†³æ–¹æ¡ˆï¼š
# - é™ä½å­¦ä¹ ç‡
# - å¢åŠ  warmup_steps
# - ä½¿ç”¨æ¢¯åº¦è£å‰ª
# - æ£€æŸ¥æ•°æ®å½’ä¸€åŒ–
```

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **VQ-VAE**: Neural Discrete Representation Learning (van den Oord et al., 2017)
2. **DDPM**: Denoising Diffusion Probabilistic Models (Ho et al., 2020)
3. **DDIM**: Denoising Diffusion Implicit Models (Song et al., 2020)
4. **DMD**: Distribution Matching Distillation (Yin et al., 2024)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

---

**æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªç ”ç©¶æ€§è´¨çš„å®ç°ï¼Œç”¨äºæ¢ç´¢é‡åŒ–æ‰©æ•£æ¨¡å‹åœ¨è§†é¢‘ç”Ÿæˆä¸­çš„åº”ç”¨ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å‰ï¼Œè¯·è¿›è¡Œå……åˆ†çš„æµ‹è¯•å’ŒéªŒè¯ã€‚

